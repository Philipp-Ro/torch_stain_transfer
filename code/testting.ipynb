{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import os\n",
    "\n",
    "path = 'C:/Users/phili/OneDrive/Uni/WS_22/Masterarbeit/Masterarbeit_Code_Philipp_Rosin/Data_set_BCI_challange/train/HE_imgs/HE'\n",
    "img_name = '00000_train_1+.png'\n",
    "HE_img_path = os.path.join(path, img_name)\n",
    "HE_img = read_image(HE_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "kernel_size, stride = 1024,1024\n",
    "patches = HE_img .unfold(1, kernel_size, stride).unfold(2, kernel_size, stride)\n",
    "patches = patches.contiguous().view(patches.size(0), -1, kernel_size, kernel_size)\n",
    "print(patches.shape) # channels, patches, kernel_size, kernel_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,activation='relu',batch_norm=True):\n",
    "        super(ConvBlock,self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size,output_size,kernel_size,stride,padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out\n",
    "            \n",
    "class DeconvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,output_padding=0,activation='relu',batch_norm=False):\n",
    "        super(DeconvBlock,self).__init__()\n",
    "        self.deconv = torch.nn.ConvTranspose2d(input_size,output_size,kernel_size,stride,padding,output_padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.   relu = torch.nn.ReLU(True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.deconv(x))\n",
    "        else:\n",
    "            out = self.deconv(x)\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 100, 100])\n",
      "torch.Size([1, 3, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "# H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
    "\n",
    "input = torch.rand([1,3,100,100])\n",
    "\n",
    "block1 =  torch.nn.Conv2d(3,3,kernel_size=3,stride=1,padding=1)\n",
    "output = block1(input)\n",
    "print(input.shape)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self,input_channels,step_num,num_filter,kernel_size):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        #Reflection padding\n",
    "        if kernel_size == 7:\n",
    "            self.padding = torch.nn.ReflectionPad2d(3)\n",
    "        elif kernel_size == 3:\n",
    "            self.padding = torch.nn.ReflectionPad2d(1)\n",
    "        else:\n",
    "            print('KERNEL_SIZE SHOULD BE EITHER 3 OR 7 FOR THE GENERATORMODELS')\n",
    "\n",
    "            \n",
    "        for i in range(step_um):\n",
    "            self.deconv = torch.nn.ConvTranspose2d(input_channels,output_chan,kernel_size,stride,padding,output_padding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d960cb169598afdf3e07f36ef921bb5a4f876badc557409f77a22927d6dd7515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
